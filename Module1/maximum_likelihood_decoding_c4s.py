# -*- coding: utf-8 -*-
"""Maximum_Likelihood_Decoding_C4S.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1KU6Zc5v16BXHtZng8ZffkUlXepGSlMWV

## **Traditional (Maximum Likelihood Decoding)**

# Loading Libraries
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import sys

"""# Loading codebook file

Loading codebook file from the generated codewords and we separate the data to codeword and message.
"""

def load_codebook(fname):
  df = pd.read_csv(fname)
  y = df[["x0", "x1", "x2", "x3", "x4", "x5", "x6"]].values
  m = df[["m0", "m1", "m2", "m3"]].values
  file_size = y.shape[0]
  return y, m, file_size

"""# Maximum Likelihood Decoding

We first generate the all possible codewords by the generator matrix. Next, we calculate the norm between received codeword and all possible codeword. We make the decision (m_hat) by choosing the one with minimum norm.
"""

def ML_decode(y):
  # type your own code
  # construct generator matrix
  G = np.array([[1, 0, 0, 0, 1, 1, 0],
                [0, 1, 0, 0, 1, 0, 1],
                [0, 0, 1, 0, 0, 1, 1],
                [0, 0, 0, 1, 1, 1, 1]])
  # construct all possible message
  possibleMes=np.array([[0,0,0,0],
                        [0,0,0,1],
                        [0,0,1,0],
                        [0,0,1,1],
                        [0,1,0,0],
                        [0,1,0,1],
                        [0,1,1,0],
                        [0,1,1,1],
                        [1,0,0,0],
                        [1,0,0,1],
                        [1,0,1,0],
                        [1,0,1,1],
                        [1,1,0,0],
                        [1,1,0,1],
                        [1,1,1,0],
                        [1,1,1,1]])
  # construct all possible codeword
  possibleCw = possibleMes.dot(G) %2
  # Mapping the codeword 0, 1 to -1, 1
  d = np.zeros(possibleCw.shape)
  d[possibleCw==0]=-1
  d[possibleCw==1]=1
  # Find the codeword which has the minimum norm
  m_hat=[]
  for item in y:
    distancelist=[]
    for i in range(len(d)):
      dis=0
      for j in range(len(d[i])):
        dis+=(item[j]-d[i][j])**2
      distancelist.append(dis)
    minindex=distancelist.index(min(distancelist))
    m_hat.append(list(possibleMes[minindex]))

  # print(m_hat)
  return m_hat

from google.colab import drive
drive.mount('/content/drive')

"""Next, we compare our recovered signal m_hat and message m. If they are the same, it means we received the signal correctly. We calculated the symbol error rate to see how our decoding scheme performed.

# Performance Evaluation

We go through all codewords to calculate the symbol error rate and bit error rate.
"""

def calculate_error(m_hat, m):  
    # print(m)
    block_err = 0
    bit_err=0;
    for i in range(len(m)):
      berr=False
      for j in range(len(m[i])):
        if(m[i][j]!=m_hat[i][j]):
          bit_err+=1
          berr=True
        if(berr):
          block_err+=1
    return block_err, bit_err

"""# Main Function"""

# SNR setting
SNR_start = 0
SNR_end = 7
step_size = 1
SNR = np.arange(SNR_start,SNR_end+1,step_size)
length_SNR = len(SNR)
BLER = np.zeros(length_SNR)
BER = np.zeros(length_SNR)

# main
for i in range(length_SNR):
  fname = "codeword_file_SNR="+str(SNR[i])+".csv"

  # type your own code (apply the defined function)
  # load codeword
  y,m,file_size=load_codebook(fname)
  # maximum likelihood decoding
  m_hat=ML_decode(y)
  # calculate error
  block_err,bit_err=calculate_error(m_hat,m)

  BER[i] = bit_err/4/file_size
  BLER[i] = block_err/file_size
  print(i,"/",len(SNR)-1)
# Fig plot
BER_uncoded = [0.07721, 0.05723, 0.03774, 0.02324, 0.01186, 0.00549, 0.00246, 0.00077]
EbN0dBs = np.arange(start=SNR_start,stop=SNR_end+1,step=step_size)
fig1 = plt.figure()
plt.semilogy(EbN0dBs,BER,color='r',marker='o',linestyle='-',label='ML Decoding')
plt.semilogy(EbN0dBs,BER_uncoded,color='b',marker='x',linestyle='-',label='Uncoded')
plt.xlabel('$E_b/N_0(dB)$');plt.ylabel('BER ($P_b$)')
plt.title('Probability of bit error over AWGN channel')
plt.xlim(SNR_start,SNR_end);plt.grid(True);
plt.legend()
plt.show()
print("Bit Error Rate:", BER)
fig2 = plt.figure()
plt.semilogy(EbN0dBs,BLER,color='r',marker='o',linestyle='-',label='ML Decoding')
plt.xlabel('$E_b/N_0(dB)$');plt.ylabel('BLER ($P_b$)')
plt.title('Probability of block error over AWGN channel')
plt.xlim(SNR_start,SNR_end);plt.grid(True);
plt.legend()
plt.show()
print("Block Error Rate:", BLER)
#print("Your name and the date you demo.")