# -*- coding: utf-8 -*-
"""Deep_Learning_C4S.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1SChhpFIGDOCbBlzPp4jgV2ZqoL1jynSj

# Loading Libraries
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import tensorflow as tf

"""# Loading codebook file"""

def load_codebook(fname):
  df = pd.read_csv(fname)
  y = df[["x0", "x1", "x2", "x3", "x4", "x5", "x6"]].values
  m = df[["m0", "m1", "m2", "m3"]].values
  file_size = y.shape[0]
  m_modified = np.zeros(file_size)
  for i in range(file_size):
    m_modified[i] += m[i,0]*8+m[i,1]*4+m[i,2]*2+m[i,3]*1
  return y, m_modified, file_size

"""**Splitting** data into training and testing"""

def splitting_data(y,m,rate,file_size):
  train_size = round(file_size*rate)
  test_size = file_size - train_size
  train_y = y[0:train_size,:]
  train_m = m[0:train_size]
  test_y = y[train_size:file_size,:]
  test_m = m[train_size:file_size]
  return train_y, train_m, test_y, test_m, train_size, test_size

"""# Compiling the model"""

def model_compile(model,SNR):
    # Set the optimizer and learning rate
    LR=0.01
    if(SNR>=4):
      LR=0.001*3
    optimizer = tf.keras.optimizers.Adam(learning_rate=LR)
    
    # Compile the model
    model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])
    
    return model

SNR_start = 0
SNR_end = 7
step_size = 1
SNR = np.arange(SNR_start,SNR_end+1,step_size)
length_SNR = len(SNR)
BLER = np.zeros(length_SNR)
rate = 0.3 # training data rate
for i in range(length_SNR):
    fname = "codeword_file_SNR="+str(SNR[i])+".csv"
    [y,m,file_size] = load_codebook(fname)
    [train_y,train_m,test_y,test_m,train_size,test_size] = splitting_data(y,m,rate,file_size)

    unique_category_count = 16
    train_m_OneHot=tf.one_hot(train_m, unique_category_count)
    test_m_OneHot=tf.one_hot(test_m, unique_category_count)

    # Define and compile the model

    inputs = tf.keras.layers.Input(shape=(7,))
    
    x = tf.keras.layers.Dense(128, activation='relu')(inputs)
    x = tf.keras.layers.Dense(64, activation='relu')(x)
    x = tf.keras.layers.Dense(32, activation='relu')(x)
    # Define the output layer
    outputs = tf.keras.layers.Dense(16, activation='softmax')(x)
    
    # Define the model
    model = tf.keras.models.Model(inputs=inputs, outputs=outputs)
    
    model_compile(model,SNR[i])
  
    if SNR[i]>=5:
        num_epochs = 6
    elif SNR[i]>=2:
        num_epochs = 40
    else:
        num_epochs = 25

    # Train the model
    history = model.fit(train_y, train_m_OneHot, epochs=num_epochs, batch_size=128, validation_data=(test_y, test_m_OneHot))

    # show the learning curve
    plt.plot(history.history['accuracy'])
    plt.plot(history.history['val_accuracy'])
    plt.legend(['training', 'validation'], loc = 'upper left')
    plt.show()

    # Predict on test data and calculate block error rate
    pred_m = model.predict(test_y)
    pred_m = np.argmax(pred_m, axis=1)
    test_error = np.sum(pred_m != test_m) / test_size
    BLER[i] = test_error
    print("BLER: ",BLER[i])
    print(i,"/",len(BLER)-1)
#Reuse the results of last time
BLER_SymdromeDecoding = [0.26725, 0.187, 0.114, 0.068, 0.036375, 0.01578, 0.005475, 0.00147, 0.00029033]
BLER_SVM = [0.191, 0.1335, 0.0755, 0.046, 0.01305, 0.00412, 0.00109, 0.000275]
BLER_ML = [1.7625e-01, 1.1075e-01, 5.8000e-02, 3.3500e-02, 1.1275e-02, 3.3550e-03, 8.0000e-04, 1.3000e-04]
#Plot BLER
EbN0dBs = np.arange(start=SNR_start,stop=SNR_end+1,step=step_size)
fig1 = plt.figure(1)
plt.semilogy(EbN0dBs,BLER,color='r',marker='o',linestyle='-',label='Deep_Learning')
plt.xlabel('$E_b/N_0(dB)$');plt.ylabel('BLER ($P_b$)')
plt.title('Probability of block error over AWGN channel')
plt.xlim(SNR_start,SNR_end);plt.grid(True);
plt.legend()
print("Block Error Rate:", BLER)
fig2 = plt.figure(2)
plt.semilogy(EbN0dBs,BLER_SymdromeDecoding[SNR_start:SNR_end+1],marker='o',linestyle='-',label='Symdrome_Decoding')
plt.semilogy(EbN0dBs,BLER_SVM[SNR_start:SNR_end+1],marker='o',linestyle='-',label='SVM')
plt.semilogy(EbN0dBs,BLER_ML[SNR_start:SNR_end+1],marker='o',linestyle='-',label='ML_Decoding')
plt.semilogy(EbN0dBs,BLER,marker='o',linestyle='-',label='Deep_Learning')
plt.xlabel('$E_b/N_0(dB)$');plt.ylabel('BLER ($P_b$)')
plt.title('Probability of block error over AWGN channel')
plt.xlim(SNR_start,SNR_end);plt.grid(True);
plt.legend()
plt.show()

"""# Main Function"""

SNR_start = 0
SNR_end = 7
step_size = 1
SNR = np.arange(SNR_start,SNR_end+1,step_size)
length_SNR = len(SNR)
BLER = np.zeros(length_SNR)
rate = 0.3 # training data rate
for i in range(length_SNR):
  fname = "codeword_file_SNR="+str(SNR[i])+".csv"
  [y,m,file_size] = load_codebook(fname)
  [train_y,train_m,test_y,test_m,train_size,test_size] = splitting_data(y,m,rate,file_size)

  unique_category_count = 16
  train_m_OneHot=tf.one_hot(train_m, unique_category_count)
  test_m_OneHot=tf.one_hot(test_m, unique_category_count)


  # -------------------------- #
  # define your model
  # -------------------------- #

  model_compile(SNR[i])
  
  if SNR[i]>=5:
    num_epochs = 5
  elif SNR[i]>=2:
    num_epochs = 40
  else:
    num_epochs = 25
  # -------------------------- #
  # training/fitting model
  # -------------------------- #
  
  # -------------------------- #
  # show the learning curve
  # -------------------------- #

  # -------------------------- #
  # predict and calculate error
  # -------------------------- #

  print("BLER: ",BLER[i])
  print(i,"/",len(BLER)-1)
#Reuse the results of last time
BLER_SymdromeDecoding = [0.26725, 0.187, 0.114, 0.068, 0.036375, 0.01578, 0.005475, 0.00147, 0.00029033]
BLER_SVM = [0.191, 0.1335, 0.0755, 0.046, 0.01305, 0.00412, 0.00109, 0.000275]
BLER_ML = [1.7625e-01, 1.1075e-01, 5.8000e-02, 3.3500e-02, 1.1275e-02, 3.3550e-03, 8.0000e-04, 1.3000e-04]
#Plot BLER
EbN0dBs = np.arange(start=SNR_start,stop=SNR_end+1,step=step_size)
fig1 = plt.figure(1)
plt.semilogy(EbN0dBs,BLER,color='r',marker='o',linestyle='-',label='Deep_Learning')
plt.xlabel('$E_b/N_0(dB)$');plt.ylabel('BLER ($P_b$)')
plt.title('Probability of block error over AWGN channel')
plt.xlim(SNR_start,SNR_end);plt.grid(True);
plt.legend()
print("Block Error Rate:", BLER)
fig2 = plt.figure(2)
plt.semilogy(EbN0dBs,BLER_SymdromeDecoding[SNR_start:SNR_end+1],marker='o',linestyle='-',label='Symdrome_Decoding')
plt.semilogy(EbN0dBs,BLER_SVM[SNR_start:SNR_end+1],marker='o',linestyle='-',label='SVM')
plt.semilogy(EbN0dBs,BLER_ML[SNR_start:SNR_end+1],marker='o',linestyle='-',label='ML_Decoding')
plt.semilogy(EbN0dBs,BLER,marker='o',linestyle='-',label='Deep_Learning')
plt.xlabel('$E_b/N_0(dB)$');plt.ylabel('BLER ($P_b$)')
plt.title('Probability of block error over AWGN channel')
plt.xlim(SNR_start,SNR_end);plt.grid(True);
plt.legend()
plt.show()